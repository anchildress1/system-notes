# Project Narratives with Technical Specs

## system-notes

System Notes is this project. It runs on Next.js with some Python support, and the entire UI was generated by an agent. I don’t know Next.js well, and that’s intentional. I let the agent handle the UI so I could focus on structure, constraints, and intent. For this proof of concept, content is sourced directly from markdown in the repository. There is no state, no memory, and no interactivity beyond reading. It is strictly read-only. In the future, search will move to Algolia, but that is out of scope for now. This is the only deployed project in the portfolio, and it exists to show how I consistently map systems and decisions rather than to act as a product.

**Technical Specs**
- Runtime: Next.js, Python
- Rendering: Next.js
- Data source (POC): Markdown
- State: None (read-only)
- Agent memory: None
- Tests: Unit tests passing
- Deployment: Google Cloud Run
- Scope: Single-page portfolio

---

## rai-lint

RAI Lint is a plugin written in both Node and Python that enforces one simple rule: if AI helped, that attribution must exist. Nothing more, nothing less. Enforcement happens at commit creation. Configuration is intentionally minimal, and output behavior is controlled by the user. It runs everywhere it makes sense to run. This is actively rolling out to a real team at work, whether they want it or not. The point isn’t debate, it’s making invisible assistance explicit.

**Technical Specs**
- Languages: Node.js, Python
- Type: Plugin (commitlint + gitlint ecosystem)
- Enforcement point: Commit creation
- Configuration: Minimal, user-controlled
- Execution: Local development and CI
- CI/Security: GitHub Actions, CodeQL, Dependabot, Sonar (enterprise)

---

## awesome-github-copilot

Awesome GitHub Copilot is an experimental sharing layer. Everything starts locally. I build agents, prompts, and skills for my own workflows first. Once something survives iteration, feedback, and real use, it gets shared informally. Only after that does it get ported into the public Awesome Copilot repo. This repo is curated manually and evolves as models change. If something stops being useful, it doesn’t belong here.

**Technical Specs**
- Format: Markdown + configuration artifacts
- Scope: Copilot prompts, agents, skills
- Maintenance: Manual curation
- Workflow: Local-first → feedback → public port
- CI: Linting, formatting, conventional commits

---

## eslint-config-echo

Echo is an ESLint plugin focused entirely on consolidating rules so I can stop repeating myself. It’s Node-only, not published yet, and designed for a single repository at a time. It prefers Sonar, allows Prettier, uses Jest for testing, and provides fallbacks where needed. Users can configure it because that’s the whole point of making it a plugin. It exists to reduce drift and friction, not to be clever.

**Technical Specs**
- Language: Node.js
- Type: ESLint plugin
- Scope: Single repository
- Publication status: Not published
- Test runner: Jest
- Formatter support: Prettier
- Static analysis: Sonar (preferred)
- Configuration: User-configurable
- CI/Security: GitHub Actions, enterprise baseline

---

## underfoot-underground-travel-planner

Underfoot started as a hackathon project using n8n and Bright Data, which worked until cost became a problem outside challenge constraints. That forced a rethink. I decided to push a separate AI solution to its absolute limits instead. In the process, I needed to test orchestration, which led to rewriting the entire project. The UI, database, and backend were rebuilt using Python, React, and Supabase. Inputs are mixed API and scraping. Output is strictly a chatbot that returns React-like answer lists. It is not finished. There are conflicts. The blocker isn’t design or direction, it’s time.

**Technical Specs**
- Backend: Python
- Frontend: React
- Database: Supabase
- Data sources: APIs + scraping (mixed)
- Orchestration: Custom AI orchestration
- Output: Chatbot only
- Response format: React-like lists
- Status: In progress, unresolved conflicts

---

## checkmark-copilot-chat

This was an early attempt to build a Copilot extension that wasn’t tied to VS Code, because most of my team works in IntelliJ. It was likely written in Node and designed specifically as a Copilot extension rather than a VS Code extension. The core blocker was GitHub’s inability at the time to persist context modifications across turns. That limitation killed the idea. The project has since been sunset, but the core idea survived and later reappeared in Awesome GitHub Copilot as installable prompts, agents, and instructions.

**Technical Specs**
- Language: Node.js (best recollection)
- Type: Copilot extension
- IDE target: VS Code and IntelliJ via Copilot
- Core limitation: No persistence across turns
- Status: Sunset

---

## delegate-action

Delegate is a GitHub Action written mostly in YAML with Node runtimes tested across versions 20 through 24. It allows users to pass a prompt via an existing file in the repository so GitHub can scan it first. The prompt is then sanitized for known injection markers, and the flow is rejected if any are found. The action mimics a coding agent to analyze code changes and identify documentation updates, opening a new draft pull request with a new commit and signing the actor as the reviewer. It uses a personal PAT because service accounts aren’t viable. This is a proof of concept and an innovation project at work. The biggest blocker is that the GitHub CLI does not work with the coding agent.

**Technical Specs**
- Type: GitHub Action
- Primary format: YAML
- Runtime: Node.js (tested 20–24)
- Trigger: Workflow / PR-based
- Input: Existing repo file
- Security: Prompt sanitization and injection detection
- Auth: Personal PAT
- Output: New commit + draft PR
- Status: POC

---

## devto-mirror

DevToMirror is a Python utility designed to make technical writing discoverable by both humans and AI. It runs on a GitHub Actions schedule shortly after my weekly post deadlines and targets DEV only. Each run pulls in new content and outputs static HTML to a GitHub Pages branch. There is also a manual workflow dispatch to force a full refresh. The output includes robots.txt, a sitemap, structured markup, and social cards. It’s intentionally simple: configure it, schedule it, and forget about it.

**Technical Specs**
- Language: Python
- Trigger: GitHub Actions (scheduled + manual)
- Target: DEV only
- Output: Static HTML
- Hosting: GitHub Pages
- SEO/Discovery: robots.txt, sitemap, structured data, social cards

---

## my-hermantic-agent

Hermes is a fully local, self-hosted agentic system with no absolute prohibitions. Guardrails are defined entirely by the system prompt and change depending on what I’m exploring. Right now the focus is memory, so it isn’t doing much else. That’s fine. This is a zero-stakes playground by design. It’s where I learn without pressure and without expectations of polish.

**Technical Specs**
- Type: Self-hosted agentic system
- Scope: Fully local
- Guardrails: System-prompt driven
- State: Experimental
- Current focus: Memory
- Deployment: None
